{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mtzig/badwriting_OCR/blob/main/iam_baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5c7wrVTPQPcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cf10b8c-767b-448d-fa67-ce485c73890a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2Awl5trS8oK",
        "outputId": "77750683-7102-4e28-90d0-007986dc376b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iam_path = '../drive/MyDrive/semester2/cs766/iam_dataset'"
      ],
      "metadata": {
        "id": "phhJYSIIZJuk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %cd drive/MyDrive/semester2/cs766/iam_dataset"
      ],
      "metadata": {
        "id": "oi4Ce8_HTssY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %mkdir sentences\n",
        "# !tar -xf sentences.tar -C sentences"
      ],
      "metadata": {
        "id": "N82liAmuT3u4"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %mkdir lines\n",
        "# !tar -xf lines.tar -C lines"
      ],
      "metadata": {
        "id": "Lm1e7jLUl6_F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %mkdir ascii\n",
        "# !tar -xf ascii.tar -C ascii"
      ],
      "metadata": {
        "id": "SURFmVRfZ_wU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "lf3UOJg2QPcN",
        "outputId": "dfecc1d3-6b87-485a-c140-da4daf1f7116",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'badwriting_OCR'...\n",
            "remote: Enumerating objects: 291, done.\u001b[K\n",
            "remote: Counting objects: 100% (99/99), done.\u001b[K\n",
            "remote: Compressing objects: 100% (64/64), done.\u001b[K\n",
            "remote: Total 291 (delta 32), reused 91 (delta 28), pack-reused 192\u001b[K\n",
            "Receiving objects: 100% (291/291), 8.21 MiB | 16.70 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "Updating files: 100% (156/156), done.\n",
            "/content/badwriting_OCR\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/mtzig/badwriting_OCR.git\n",
        "%cd /content/badwriting_OCR/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers\n",
        "!pip install -q datasets jiwer"
      ],
      "metadata": {
        "id": "DCMvuwxlQfOM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HxTROWN-QPcN",
        "outputId": "8a887dea-518a-4785-f9e6-9e06ee9bd276",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/badwriting_OCR/utils/model_utils.py:12: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  cer_metric = load_metric(\"cer\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for cer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/cer/cer.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
          ]
        }
      ],
      "source": [
        "from utils import model_utils\n",
        "from transformers import AdamW\n",
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZM2LeQNuQPcN"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code to generate csv file with iam file names and paths"
      ],
      "metadata": {
        "id": "FvK2pwBrhy4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make a csv file with the file names and text starting from directory sentences\n",
        "# Filename                       Text\n",
        "# a01/a01-000u/a01-000u-00.png   A MOVE to stop...\n",
        "\n",
        "# import csv\n",
        "\n",
        "# data = [['file_name', 'text']]\n",
        "\n",
        "# with open(iam_path + '/ascii/lines.txt') as file:\n",
        "#   for line in file:\n",
        "#     if line[0] != '#': # ignore instructions\n",
        "#       file_name = line.split()[0]\n",
        "\n",
        "#       dash1 = file_name.find('-')\n",
        "#       dash2 = file_name.find('-', dash1+1)\n",
        "\n",
        "#       file_name = file_name[:dash1]+'/'+file_name[:dash2]+'/'+file_name+'.png'\n",
        "\n",
        "#       text = line.split()[-1]\n",
        "#       text = ' '.join(text.split('|'))\n",
        "#       data.append([file_name, text])\n",
        "\n",
        "# csv_file = iam_path + '/iam_data.csv'\n",
        "\n",
        "# with open(csv_file, mode='w', newline='') as file:\n",
        "#   writer = csv.writer(file)\n",
        "#   writer.writerows(data)"
      ],
      "metadata": {
        "id": "4DfzN7THXb9o"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ho-A-WLbQPcO",
        "outputId": "f45247fa-ac8a-4664-846d-cd05f6734244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-small-handwritten and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "train_dataloader,eval_dataloader = model_utils.get_dataloaders(dataset_type='iam', root=iam_path)\n",
        "model = model_utils.getModel(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrOCRProcessor\n",
        "import pandas as pd\n",
        "\n",
        "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-handwritten\")\n",
        "\n",
        "def compute_outputs(pred_ids, label_ids):\n",
        "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
        "    label_ids[label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "    return pred_str, label_str"
      ],
      "metadata": {
        "id": "hgpj6bPIUKWs",
        "outputId": "9546f4f9-7f26-4eba-9208-9661748f43f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_preds, base_labels = [], []\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(eval_dataloader):\n",
        "    # run batch generation\n",
        "    outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
        "    p, l = compute_outputs(outputs, batch[\"labels\"].to(device))\n",
        "    base_preds.extend(p)\n",
        "    base_labels.extend(l)\n",
        "\n",
        "base_df = pd.DataFrame(data={'preds':base_preds, 'lables':base_labels})\n",
        "base_df.to_csv('base.csv', index=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UnDb4ydoS16Z",
        "outputId": "8597e985-5ee4-4895-c10c-0dcf13121de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "e378b1483bc64dca858447a8753f0216",
            "f875d46ac4f847d19d31a0ad4b173012",
            "4d7f7ec7d9d34d9d9c81ee324ece6fc0",
            "5055a838267a4ef38e32c7306362551e",
            "63072c5307ee4792baa9de9bb07cb1ea",
            "1bf69b36dade4eceba7f79fb0367602c",
            "61d4c006527b4152b7659115f63b1b0c",
            "8c13f228b8704290b6c2329354a6591a",
            "73a140446dee44d9975d987a8070aed9",
            "f72d0093f0bc4c79af6468dac7e57634",
            "2b43efaa9e3c431ebbf6b0d6ff34ced7"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/668 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e378b1483bc64dca858447a8753f0216"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1339: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cy7ubW63QPcO"
      },
      "outputs": [],
      "source": [
        "full_train_cer = []\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "   # train\n",
        "   model.train()\n",
        "   train_loss = 0.0\n",
        "   for batch in tqdm(train_dataloader):\n",
        "      # get the inputs\n",
        "      for k,v in batch.items():\n",
        "        batch[k] = v.to(device)\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(**batch)\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "\n",
        "   print(f\"Loss after epoch {epoch}:\", train_loss/len(train_dataloader))\n",
        "\n",
        "   # evaluate\n",
        "   model.eval()\n",
        "   valid_cer = 0.0\n",
        "   with torch.no_grad():\n",
        "     for batch in tqdm(eval_dataloader):\n",
        "       # run batch generation\n",
        "       outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
        "       # compute metrics\n",
        "       cer = model_utils.compute_cer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
        "       valid_cer += cer\n",
        "\n",
        "   full_train_cer.append(cer)\n",
        "\n",
        "   print(\"Validation CER:\", valid_cer / len(eval_dataloader))\n",
        "\n",
        "model.save_pretrained(\".\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBmlfoJ3QPcO"
      },
      "outputs": [],
      "source": [
        "full_preds, full_labels = [], []\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(eval_dataloader):\n",
        "    # run batch generation\n",
        "    outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
        "    p, l = compute_outputs(outputs, batch[\"labels\"].to(device))\n",
        "    full_preds.extend(p)\n",
        "    full_labels.extend(l)\n",
        "\n",
        "full_df = pd.DataFrame(data={'preds':full_preds, 'lables':full_labels})\n",
        "full_df.to_csv('full.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_utils.getModel(device)\n",
        "# for pn, p in model.named_parameters():\n",
        "#   if pn != 'decoder.output_projection.weight':\n",
        "#     p.requires_grad = False\n",
        "\n",
        "for pn, p in model.named_parameters():\n",
        "  if pn.startswith('encoder'):\n",
        "    p.requires_grad = False"
      ],
      "metadata": {
        "id": "Oewkq2UsXHl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freeze_train_cer = []\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "for epoch in range(10):  # loop over the dataset multiple times\n",
        "   # train\n",
        "   model.train()\n",
        "   train_loss = 0.0\n",
        "   for batch in tqdm(train_dataloader):\n",
        "      # get the inputs\n",
        "      for k,v in batch.items():\n",
        "        batch[k] = v.to(device)\n",
        "\n",
        "      # forward + backward + optimize\n",
        "      outputs = model(**batch)\n",
        "      loss = outputs.loss\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "\n",
        "   print(f\"Loss after epoch {epoch}:\", train_loss/len(train_dataloader))\n",
        "\n",
        "   # evaluate\n",
        "   model.eval()\n",
        "   valid_cer = 0.0\n",
        "   with torch.no_grad():\n",
        "     for batch in tqdm(eval_dataloader):\n",
        "       # run batch generation\n",
        "       outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
        "       # compute metrics\n",
        "       cer = model_utils.compute_cer(pred_ids=outputs, label_ids=batch[\"labels\"])\n",
        "       valid_cer += cer\n",
        "\n",
        "   freeze_train_cer.append(cer)\n",
        "\n",
        "   print(\"Validation CER:\", valid_cer / len(eval_dataloader))\n",
        "\n",
        "model.save_pretrained(\".\")"
      ],
      "metadata": {
        "id": "714gLcqHXIld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "freeze_preds, freeze_labels = [], []\n",
        "with torch.no_grad():\n",
        "  for batch in tqdm(eval_dataloader):\n",
        "    # run batch generation\n",
        "    outputs = model.generate(batch[\"pixel_values\"].to(device))\n",
        "    p, l = compute_outputs(outputs, batch[\"labels\"].to(device))\n",
        "    freeze_preds.extend(p)\n",
        "    freeze_labels.extend(l)\n",
        "\n",
        "freeze_df = pd.DataFrame(data={'preds':freeze_preds, 'lables':freeze_labels})\n",
        "freeze_df.to_csv('freeze.csv', index=False)"
      ],
      "metadata": {
        "id": "HYXAvwMyXtgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cer_df = pd.DataFrame(data={'full':full_train_cer, 'freeze':freeze_train_cer})\n",
        "cer_df.to_csv('cer.csv', index=False)"
      ],
      "metadata": {
        "id": "xKx7hJtLYDhJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "iam_baselines.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e378b1483bc64dca858447a8753f0216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f875d46ac4f847d19d31a0ad4b173012",
              "IPY_MODEL_4d7f7ec7d9d34d9d9c81ee324ece6fc0",
              "IPY_MODEL_5055a838267a4ef38e32c7306362551e"
            ],
            "layout": "IPY_MODEL_63072c5307ee4792baa9de9bb07cb1ea"
          }
        },
        "f875d46ac4f847d19d31a0ad4b173012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bf69b36dade4eceba7f79fb0367602c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_61d4c006527b4152b7659115f63b1b0c",
            "value": "â€‡â€‡7%"
          }
        },
        "4d7f7ec7d9d34d9d9c81ee324ece6fc0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c13f228b8704290b6c2329354a6591a",
            "max": 668,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_73a140446dee44d9975d987a8070aed9",
            "value": 45
          }
        },
        "5055a838267a4ef38e32c7306362551e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72d0093f0bc4c79af6468dac7e57634",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2b43efaa9e3c431ebbf6b0d6ff34ced7",
            "value": "â€‡44/668â€‡[01:12&lt;18:48,â€‡â€‡1.81s/it]"
          }
        },
        "63072c5307ee4792baa9de9bb07cb1ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf69b36dade4eceba7f79fb0367602c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61d4c006527b4152b7659115f63b1b0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c13f228b8704290b6c2329354a6591a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73a140446dee44d9975d987a8070aed9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f72d0093f0bc4c79af6468dac7e57634": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b43efaa9e3c431ebbf6b0d6ff34ced7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}